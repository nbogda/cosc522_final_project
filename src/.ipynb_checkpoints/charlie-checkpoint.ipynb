{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "import random as rand\n",
    "import sys\n",
    "import collections\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readInCSV():\n",
    "    train = pd.read_csv(\"../data/PCA_split_data_train.csv\")\n",
    "    col_names_tr = list(train.columns)\n",
    "    row_tr, columns_tr = train.shape\n",
    "    \n",
    "    test = pd.read_csv(\"../data/PCA_split_data_test.csv\")\n",
    "    col_names_test = list(test.columns)\n",
    "    row_test, columns_test = test.shape\n",
    " \n",
    "    #split data into \"labels\" and predictors (The actual trainging set was split 70-30 since the testing set has no outcomes)\n",
    "    X_tr = [] #predictors training\n",
    "    y_tr = [] #predictions training\n",
    "    X_test = [] #features testing\n",
    "    y_test = [] #predicitions testing\n",
    "    \n",
    "    for index, row in train.iterrows():\n",
    "        y_tr.append(list(row.ix[1:13]))\n",
    "        X_tr.append(list(row.ix[13:]))\n",
    "        \n",
    "    for index, row in test.iterrows():\n",
    "        y_test.append(list(row.ix[1:13]))\n",
    "        X_test.append(list(row.ix[13:]))\n",
    "        \n",
    "    return X_tr,y_tr,X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr,y_tr,X_test,y_test = readInCSV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.88124979 1.85973342 1.75981817 1.62463089 2.30205666 2.82440022\n",
      " 2.98257311 3.00946801 3.29549524 3.40252322 3.47189648 3.6014681 ]\n",
      "2.7602162787727558\n"
     ]
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(random_state=0)\n",
    "regressor.fit(X_tr,y_tr)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred,multioutput='raw_values')))\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "#cross_val_score(regressor, X, y, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.58148569 1.68412589 1.5351987  1.43564457 1.74710074 1.96884323\n",
      " 2.07025245 2.20303742 2.3352524  2.63922237 2.70155399 2.76537859]\n",
      "2.1053092064943013\n"
     ]
    }
   ],
   "source": [
    "RFregr = RandomForestRegressor(max_depth=10, random_state=0,n_estimators=1000)\n",
    "RFregr.fit(X_tr,y_tr)\n",
    "y_pred = RFregr.predict(X_test)\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred,multioutput='raw_values')))\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM/SVR Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.34902169 1.41216253 1.37616898 1.31884526 1.70750222 1.95788325\n",
      " 2.05074088 2.10753728 2.23462177 2.5031306  2.59302153 2.65897147]\n",
      "1.9978418734749357\n"
     ]
    }
   ],
   "source": [
    "clf = SVR(kernel=\"rbf\",gamma='auto', C=1.0, epsilon=0.2)\n",
    "multi_clf = MultiOutputRegressor(clf)\n",
    "multi_clf.fit(X_tr,y_tr)\n",
    "y_pred = multi_clf.predict(X_test)\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred,multioutput='raw_values')))\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred)))\n",
    "#cross_val_score(clf, X, y_col_1, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP(NN) Stuff -- Note: np.abs() needs to be used on prediction because it guesses negative values sometimes... oh well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.56396127 2.50369399 2.48554303 2.19349642 2.50821333 2.74924817\n",
      " 2.60702612 2.80357631 2.77247622 2.95671674 2.98332751 3.06660366]\n",
      "2.693680194902107\n"
     ]
    }
   ],
   "source": [
    "bpnn = MLPRegressor(max_iter = 50000) #Very basic BPNN/MLP\n",
    "bpnn.fit(X_tr,y_tr)\n",
    "y_pred = bpnn.predict(X_test)\n",
    "print(np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred),multioutput='raw_values'))) #It's weird that it predicts negative vals.. oh well\n",
    "print(np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.37359479 1.52616017 1.52944453 1.44291999 1.73108605 2.02886042\n",
      " 2.04111615 2.23787946 2.30771045 2.65521729 2.65426601 2.69909518]\n",
      "2.07425264644338\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsRegressor(n_neighbors=5)\n",
    "neigh.fit(X_tr,y_tr)\n",
    "y_pred = neigh.predict(X_test)\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred,multioutput='raw_values')))\n",
    "print(np.sqrt(mean_squared_log_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression -- Note: np.abs() needs to be used on prediction because it guesses negative values sometimes... oh well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.95769238 2.06549243 1.89289802 1.7190577  2.02606517 2.26727607\n",
      " 2.3157198  2.47138278 2.63004808 2.81358877 2.86113952 3.01684548]\n",
      "2.371246565495967\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_tr,y_tr)\n",
    "y_pred = reg.predict(X_test)\n",
    "print(np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred),multioutput='raw_values')))\n",
    "print(np.sqrt(mean_squared_log_error(y_test, np.abs(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
